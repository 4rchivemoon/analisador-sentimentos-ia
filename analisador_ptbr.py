#!/usr/bin/env python3
# -*- coding: utf-8 -*-

print("ğŸ‡§ğŸ‡· ANALISADOR DE SENTIMENTOS - PORTUGUÃŠS BRASILEIRO")
print("=" * 60)

import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

print("âœ… Iniciando analisador para portuguÃªs...")

# Dados ESPECÃFICOS para portuguÃªs brasileiro
print("\nğŸ“š CARREGANDO DATASET EM PORTUGUÃŠS...")

textos_treinamento = [
    # ğŸ˜Š POSITIVOS - ExpressÃµes tÃ­picas do Brasil
    "achei muito bom top demais",
    "gostei bastante curti muito", 
    "maneiro demais show de bola",
    "excelente produto recomendo",
    "muito bom mesmo adorei",
    "qualidade top nota dez",
    "superou expectativas incrÃ­vel",
    "maravilhoso fantÃ¡stico sensacional",
    "barato e bom custo benefÃ­cio",
    "atendimento perfeito impecÃ¡vel",
    "produto chegou rÃ¡pido",
    "funciona perfeitamente zero defeitos",
    "prÃ¡tico e eficiente amei",
    "vale cada centavo compraria de novo",
    "melhor compra do ano",
    "surpreendeu positivamente",
    
    # ğŸ˜  NEGATIVOS - ExpressÃµes tÃ­picas do Brasil
    "que porcaria lixo completo",
    "pÃ©ssimo produto nÃ£o comprem",
    "dinheiro jogado fora",
    "arrependimento total furada",
    "horrÃ­vel terrÃ­vel decepcionante", 
    "veio com defeito quebra fÃ¡cil",
    "atendimento horroroso pÃ©ssimo",
    "nÃ£o funciona direito problema",
    "qualidade inferior ruim",
    "golpe enganaÃ§Ã£o mentira",
    "perda de tempo dinheiro",
    "pessimo atendimento demorado",
    "produto veio errado errado",
    "nÃ£o recomendo pra ninguÃ©m",
    "pÃ©ssima experiÃªncia nunca mais",
    "estragou rÃ¡pido quebrou"
]

rotulos_treinamento = [1] * 16 + [0] * 16  # 16 positivos, 16 negativos

print(f"ğŸ“Š Dataset carregado: {len(textos_treinamento)} frases em portuguÃªs")

# PrÃ©-processamento especÃ­fico para portuguÃªs
def preprocessar_ptbr(texto):
    texto = texto.lower()
    
    # Remover caracteres especiais mas manter acentos
    texto = re.sub(r'[^\w\sÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]', '', texto)
    
    # ExpressÃµes comuns no Brasil (manter como uma Ãºnica "palavra")
    expressoes = {
        'show de bola': 'showdebola',
        'top demais': 'topdemais', 
        'dinheiro jogado fora': 'dinheirojogadofora',
        'nota dez': 'notadez',
        'custo benefÃ­cio': 'custobeneficio',
        'zero defeitos': 'zerodefeitos'
    }
    
    for exp, substituicao in expressoes.items():
        texto = texto.replace(exp, substituicao)
    
    return texto

print("ğŸ”§ Aplicando prÃ©-processamento para portuguÃªs...")
textos_processados = [preprocessar_ptbr(texto) for texto in textos_treinamento]

# Criar modelo otimizado para portuguÃªs
modelo_ptbr = make_pipeline(
    CountVectorizer(
        ngram_range=(1, 2),  # Captura palavras simples e combinaÃ§Ãµes
        max_features=100     # Foca nas palavras mais importantes
    ),
    MultinomialNB()
)

print("ğŸ§  TREINANDO MODELO PARA PORTUGUÃŠS...")
modelo_ptbr.fit(textos_processados, rotulos_treinamento)
print("âœ… Modelo treinado com sucesso!")

# FunÃ§Ã£o de anÃ¡lise com detalhes em portuguÃªs
def analisar_detalhado_ptbr(frase):
    frase_processada = preprocessar_ptbr(frase)
    predicao = modelo_ptbr.predict([frase_processada])[0]
    probabilidades = modelo_ptbr.predict_proba([frase_processada])[0]
    
    sentimento = "ğŸ˜Š POSITIVO" if predicao == 1 else "ğŸ˜  NEGATIVO"
    confianca = probabilidades[predicao] * 100
    
    # Analisar palavras especÃ­ficas do portuguÃªs
    palavras_positivas_br = ['top', 'show', 'maneiro', 'curti', 'gostei', 'amei', 'adorei', 'incrÃ­vel']
    palavras_negativas_br = ['porcaria', 'pÃ©ssimo', 'horroroso', 'furada', 'arrependimento', 'golpe']
    
    palavras_detectadas = []
    for palavra in frase.lower().split():
        if palavra in palavras_positivas_br:
            palavras_detectadas.append(f"â•'{palavra}'")
        elif palavra in palavras_negativas_br:
            palavras_detectadas.append(f"â–'{palavra}'")
    
    return sentimento, confianca, palavras_detectadas

# Testar com expressÃµes brasileiras
print("\nğŸ§ª TESTANDO COM EXPRESSÃ•ES BRASILEIRAS:")
print("-" * 50)

testes_brasileiros = [
    "achei top demais show de bola",
    "que porcaria dinheiro jogado fora", 
    "produto maneiro curti muito",
    "golpe completo furada",
    "custo benefÃ­cio excelente",
    "atendimento horroroso pÃ©ssimo",
    "nota dez recomendo",
    "arrependimento total nÃ£o comprem"
]

for frase in testes_brasileiros:
    sentimento, confianca, palavras = analisar_detalhado_ptbr(frase)
    
    print(f"ğŸ“ '{frase}'")
    print(f"   â†’ {sentimento} ({confianca:.1f}% de confianÃ§a)")
    if palavras:
        print(f"   ğŸ” {', '.join(palavras)}")
    print()

# EstatÃ­sticas em portuguÃªs
acuracia_ptbr = modelo_ptbr.score(textos_processados, rotulos_treinamento)
print(f"ğŸ“ˆ AcurÃ¡cia para portuguÃªs: {acuracia_ptbr * 100:.1f}%")

# Teste interativo BR
print("\nğŸ”„ MODO INTERATIVO BR (digite 'sair' para parar)")
print("-" * 50)

while True:
    try:
        user_input = input("\nğŸ˜Š Digite uma frase em portuguÃªs: ")
        
        if user_input.lower() == 'sair':
            print("ğŸ‘‹ Valeu! AtÃ© mais!")
            break
        
        if user_input.strip():
            sentimento, confianca, palavras = analisar_detalhado_ptbr(user_input)
            print(f"   ğŸ¯ {sentimento} ({confianca:.1f}% de confianÃ§a)")
            
            if confianca < 70:
                print("   âš ï¸  ConfianÃ§a baixa - talvez seja neutro?")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Programa encerrado pelo usuÃ¡rio!")
        break

print("\nâœ¨ Analisador de sentimentos em portuguÃªs brasileiro - PRONTO! ğŸŠ")